{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TIVCSJV-7kDs"
   },
   "source": [
    "## Task 1 \n",
    "\n",
    "Write a parser that can read all the lines of the file `holbrook.txt` and print out for each line the original (misspelled) text, the corrected text and the indexes of any changes. The indexes refers to the index of the words in the sentence. In the example given, there is only an error in the 10th word and so the list of indexes is [9]. It is not necessary to analyze where the error occurs inside the word.\n",
    "\n",
    "Then split your data into a test set of 100 lines and a training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import itertools\n",
    "import time\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RznCZ1mw7mfk"
   },
   "outputs": [],
   "source": [
    "lines = open(\"holbrook.txt\").readlines()\n",
    "data = []\n",
    "\n",
    "#assert(data[2] == {\n",
    "#    'original': ['I', 'have', 'four', 'in', 'my', 'Family', 'Dad', 'Mum', 'and', 'siter', '.'], \n",
    "#    'corrected': ['I', 'have', 'four', 'in', 'my', 'Family', 'Dad', 'Mum', 'and', 'sister', '.'], \n",
    "#    'indexes': [9]\n",
    "#})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function for taking one line at a time and return dictionary with original , corrected and indexes of the error\n",
    "\n",
    "def sent_parser(line):\n",
    "   \n",
    "    corrected=[]\n",
    "    original=[]\n",
    "    c=0            ## counter for storing index values where pipe operator is present\n",
    "    index=[]      ## list for storing the index value of the misspelled words\n",
    "    for word in line.split():               ## for iterating through words in the line or sentence\n",
    "        if '|' in word:              ## if '|' is present in the word then \n",
    "            index.append(c)            ## return index by the value of counter 'c' at which correction is present\n",
    "            \n",
    "                \n",
    "            ind=word.index('|')        #storing the index value of '|' in 'ind' variable and indexing is done for the correct and incorrect word \n",
    "            corrected.append(word[ind+1:])   #and the value is stored in the corrected and incorrect list      \n",
    "            original.append(word[:ind])\n",
    "\n",
    "        else :\n",
    "            \n",
    "            #if no correction is required then add word directly to the the corrected and incorrect list without \n",
    "            #any processing \n",
    "            \n",
    "            corrected.append(word)\n",
    "            original.append(word)\n",
    "\n",
    "        c+=1\n",
    "    \n",
    "    dict={'original':original,'corrected':corrected,'indexes':index}\n",
    "    \n",
    "    return dict\n",
    "\n",
    "def doc_parser(filename):\n",
    "    lines = open(filename).readlines()\n",
    "    data = []\n",
    "    \n",
    "    for i in lines:\n",
    "        data.append(sent_parser(i))\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calling parser function and passing the 'holbrook.txt' file in the function\n",
    "\n",
    "filename='holbrook.txt'\n",
    "\n",
    "## parser function and saving the result in data variable\n",
    "\n",
    "data=doc_parser(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(data[2] == {\n",
    "    'original': ['I', 'have', 'four', 'in', 'my', 'Family', 'Dad', 'Mum', 'and', 'siter', '.'], \n",
    "    'corrected': ['I', 'have', 'four', 'in', 'my', 'Family', 'Dad', 'Mum', 'and', 'sister', '.'], \n",
    "    'indexes': [9]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eRSX4I0H7pSC"
   },
   "source": [
    "The counts and assertions given in the following sections are based on splitting the training and test set as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Kt9aR2Gy7p1C"
   },
   "outputs": [],
   "source": [
    "test = data[:100]\n",
    "train = data[100:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### separating train correct data, test correct data and test original data in differenct lists\n",
    "\n",
    "train_correct=[i['corrected'] for i in train]\n",
    "test_correct=[i['corrected'] for i in test]\n",
    "test_original=[i['original'] for i in test] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hm5JL7cH7sLK"
   },
   "source": [
    "## **Task 2** : \n",
    "Calculate the frequency (number of occurrences), *ignoring case*, of all words and their unigram probability from the corrected *training* sentences.\n",
    "\n",
    "*Hint: use `Counter` to implement this so it may be called many times*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "train_correct_words=list(itertools.chain(*train_correct))  ## list of all words in the train_correct \n",
    "x=' '.join(train_correct_words)     \n",
    "lower=x.lower()                   \n",
    "x_words=nltk.word_tokenize(lower)\n",
    "freq=Counter(x_words)                 ##Freq has all the words with their frequency from train_correct\n",
    "train_correct_uniq=list(freq.keys())  ##list of all correct words that are unique\n",
    "total_correct=sum(freq.values()) ## total count of words in train_correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "7ge0uHS-7uEK"
   },
   "outputs": [],
   "source": [
    "def unigram(word):\n",
    "    word=word.lower()\n",
    "    dict_c=dict(freq)      ## dict of counter 'freq' created in previous cell which has the frequency of words \n",
    "                           ## occuring in train_correct each words occuring \n",
    "    return dict_c[word]\n",
    "  \n",
    "def prob(word):            ## function for calculating probability of the word\n",
    "    \n",
    "    probability=unigram(word)/total_correct\n",
    "    return probability\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your code with the following\n",
    "assert(unigram(\"me\")==87)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w8r8QYj78GPK"
   },
   "source": [
    "## **Task 3** : \n",
    "[Edit distance](https://en.wikipedia.org/wiki/Edit_distance) is a method that calculates how similar two strings are to one another by counting the minimum number of operations required to transform one string into the other. There is a built-in implementation in NLTK that works as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 956,
     "status": "ok",
     "timestamp": 1536070558621,
     "user": {
      "displayName": "John McCrae",
      "photoUrl": "//lh3.googleusercontent.com/-whXIBV_wL0Y/AAAAAAAAAAI/AAAAAAAAATE/-2hfaPZsyHM/s50-c-k-no/photo.jpg",
      "userId": "102173405218988557336"
     },
     "user_tz": -60
    },
    "id": "SV9Mu8P38IQE",
    "outputId": "9f29e22b-0f8b-4b92-9d5f-fcde3efec970"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "from nltk.metrics.distance import edit_distance\n",
    "\n",
    "# Edit distance returns the number of changes to transform one word to another\n",
    "print(edit_distance(\"hello\", \"hi\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hm46Lbiz8K8M"
   },
   "source": [
    "Write a function that calculates all words with *minimal* edit distance to the misspelled word. You should do this as follows\n",
    "\n",
    "1. Collect the set of all unique tokens in `train`\n",
    "2. Find the minimal edit distance, that is the lowest value for the function `edit_distance` between `token` and a word in `train`\n",
    "3. Output all unique words in `train` that have this same (minimal) `edit_distance` value\n",
    "\n",
    "*Do not implement edit distance, use the built-in NLTK function `edit_distance`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidates(token):\n",
    "    distance={}    ## dictionary is initalized to store minimal edit distance as values and token as the key\n",
    "       \n",
    "     \n",
    "    for i in train_correct_uniq:\n",
    "        distance[i]=edit_distance(i,token)\n",
    "\n",
    "    sort=sorted(distance.items(),key=lambda x:x[1])   ## the dict is sorted with the minimum distance in the first place\n",
    "    min_dist=sort[0][1]      ## storing the mininum value of the distance from word to token\n",
    "    sorted_dic=dict(sort)\n",
    "\n",
    "    min_dist_words=[key for key,value in sorted_dic.items() if value==min_dist]  ## list of words with the minimum distance value \n",
    "    \n",
    "    return min_dist_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your code as follows\n",
    "assert(get_candidates(\"minde\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGY-eCkN8TIM"
   },
   "source": [
    "## Task 4 :\n",
    "\n",
    "Write a function that takes a (misspelled) sentence and returns the corrected version of that sentence. The system should scan the sentence for words that are not in the dictionary (set of unique words in the training set) and for each word that is not in the dictionary choose a word in the dictionary that has minimal edit distance and has the highest *unigram probability*. \n",
    "\n",
    "*Your solution to this should involve `get_candidates`*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct(sentence):\n",
    "    correct_sent=[]\n",
    "    probability={}\n",
    "    for i in sentence:\n",
    "        \n",
    "        if i.lower() not in train_correct_uniq:\n",
    "                \n",
    "                return_word=get_candidates(i)           ## calling function get_candidates to return the words with minimal distance\n",
    "                               \n",
    "                for j in return_word:\n",
    "                    probability[j]=prob(j)   ## prob function is called to return the prbability of the given word\n",
    "                \n",
    "                sorted_prob=sorted(probability.items(),key=lambda x:x[1],reverse=True) \n",
    "                predicted_word=sorted_prob[0][0]       ##the word with the maximum probbility is returned as predicted_word\n",
    "                correct_sent.append(predicted_word)    \n",
    "\n",
    "                              \n",
    "        else:\n",
    "            correct_sent.append(i)\n",
    "            \n",
    "    return correct_sent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(correct([\"this\",\"whitr\",\"cat\"]) == ['this','white','cat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oG7jC6au8kka"
   },
   "source": [
    "## **Task 5** : \n",
    "Using the test corpus evaluate the *accuracy* of your method, i.e., how many words from your system's output match the corrected sentence (you should count words that are already spelled correctly and not changed by the system)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(test_data):\n",
    "    c_correct=0\n",
    "    ## list of sentences in the test-original\n",
    "    test_original=[test_indi['original'] for test_indi in test_data]\n",
    "\n",
    "    ## list of sentences in the test-correct\n",
    "    test_correct=[test_indi['corrected'] for test_indi in test_data]\n",
    "    total=len(list(itertools.chain(*test_correct)))\n",
    "              \n",
    "    for i in range(len(test_original)): \n",
    "        \n",
    "        \"\"\"predicted is the sentence predicted by the correct function \"\"\"\n",
    "        predict=correct(test_original[i])      \n",
    "        for j in range(len(predict)):          ## each word in predict sentence is then compared with the test_correct word\n",
    "                if predict[j]==test_correct[i][j]: \n",
    "                        c_correct +=1\n",
    "        \n",
    "        accuracy=(c_correct)/total\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for model is :  0.8237\n",
      "Wall time: 23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "acc=accuracy(test)\n",
    "print('The accuracy for model is : ', round(acc,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9b-r2JzD8_Zh"
   },
   "source": [
    "## **Task 6 :**\n",
    "\n",
    "Consider a modification to your algorithm that would improve the accuracy of the algorithm developed in Task 3 and 4\n",
    "\n",
    "* You may resources beyond those provided here.\n",
    "* You must **not use the test data** in this task.\n",
    "* Provide a short text describing what you intend to do and why. \n",
    "* Full marks for this section may be obtained without an implementation, but an implementation is preferred.\n",
    "* Your implementation should not consist of more than 50 lines of code\n",
    "\n",
    "Please note this task is marked according to: demonstration of knowledge from the lectures (10), originality and appropriateness of solution (10), completeness of description (10) and technical correctness (5)\n",
    "\n",
    "### Observations and modification to improve algorithm:\n",
    "\n",
    "- **NNP tag recognition (Named entity)**: It is observed from the dataset that there are many proper noun present in the test data which are not present in train data. Therefore, the named entities are also getting converted to the nearest matched words from the unique words of the train_correct vocabulary. A list could be created that can capture the named entity in the sentence so that we can avoid processing it in the correct function and directly append it to the list. Ex. In the test data there are some words like 'Anglia' which is converting to 'English' and also from train_original \"NIGEL THRUSH page 48\" is converting \"JILL THE page 48\".<br>Following steps are taken to capture proper nouns:<br>\n",
    "    1) the sentence is taken as input.<br>\n",
    "    2) Pos_tag has been performed.<br>\n",
    "    3) The keys with tags as 'NNP' are extracted from the sentence.<br>\n",
    "<br>\n",
    "- **Words.words()**: nltk corpus of words are used to check the whether the word is valid or not. If it is not valid then processing the word through correct function otherwise directly append it to the corrected word.\n",
    "<br>\n",
    "\n",
    "- **Not considering the numbers**: There are some numbers or digits which are converting to the most nearest number due to their non presence in the training set. I have tried not converting the strings that are number and pass them as it is in the corrected form.It is slighlty increasing the accuracy.\n",
    "<br><br>\n",
    "- **Bigram Probability**: Bigram probability (conditional probability) can be calculated for the words returned from get_candidates function and one with the highest bigram probability value. The candidate should be selected using the bigram language model. If the word is first word in the sentence then take the unigram probability otherwise go with calculating conditional bigram probability.\n",
    "<br>\n",
    "\n",
    "- **Good Turing Smoothing**: While calculating probability in case of bigram probability, if the word is not in the vocabulary, it can result in 0 probability. Therefore, smoothing techniques can be used to overcome this issue. Good turing can be helpful in place where the we have to calculate the probability of the unseen words.\n",
    "<br>\n",
    "- **Add one smoothing**: Add one smoothing was implemented for out of vocabulary words in the calculation of unigram probability. The result didn't help much though. the accuracy remained almost same.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Function created to capture the word that are proper nouns \"\"\"\n",
    "\n",
    "def named_en(sent):\n",
    "    named_e=[]\n",
    "    for i,j in nltk.pos_tag(sent):\n",
    "        if j=='NNP':\n",
    "            named_e.append(i)\n",
    "    return named_e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GLzaC6D28sK9"
   },
   "source": [
    "## **Task 7 :**\n",
    "\n",
    "Repeat the evaluation (as in Task 5) of your new algorithm and show that it outperforms the algorithm from Task 3 and 4\n",
    "\n",
    "### Evaluation:\n",
    "\n",
    "The accuracy has improved from 82.37 % to 89.99 % by making moditifications mentioned above in the previous algorithm. Implementing some changes are has increased the accuracy by 7.5 %."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import words\n",
    "\n",
    "def correct_mod(sentence):\n",
    "    correct_sent=[]\n",
    "    probability={}\n",
    "    named_ent=named_en(sentence)\n",
    "    for i in sentence:\n",
    "        \n",
    "        \"\"\"If the word is digit or is proper noun or present in train_correct vocabulary the it is not processed through correct \n",
    "        function and directly appended to the corrected sentence in correct_sent\"\"\"\n",
    "        \n",
    "        if i not in named_ent and not i.isdigit() and i not in words.words() and i.lower() not in train_correct_uniq:\n",
    "            return_word=get_candidates(i)           \n",
    "            for j in return_word:\n",
    "                probability[j]=prob(j)   ## prob function is called to return the prbability of the given word\n",
    "\n",
    "            sorted_prob=sorted(probability.items(),key=lambda x:x[1],reverse=True) \n",
    "            predicted_word=sorted_prob[0][0]       ##the word with the maximum probbility is returned as predicted_word\n",
    "            correct_sent.append(predicted_word)    \n",
    "        \n",
    "        else:\n",
    "            correct_sent.append(i)\n",
    "            \n",
    "    return correct_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_mod(test_data):\n",
    "    c_correct=0\n",
    "    ## list of sentences in the test-original\n",
    "    test_original=[test_indi['original'] for test_indi in test_data]\n",
    "\n",
    "    ## list of sentences in the test-correct\n",
    "    test_correct=[test_indi['corrected'] for test_indi in test_data]\n",
    "    total=len(list(itertools.chain(*test_correct)))\n",
    "              \n",
    "    for i in range(len(test_original)):\n",
    "        x=correct_mod(test_original[i])\n",
    "        for j in range(len(x)):\n",
    "                if x[j]==test_correct[i][j]:\n",
    "                        c_correct +=1\n",
    "        \n",
    "        accuracy=(c_correct)/total\n",
    "    \n",
    "    return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The modified accuracy is :',round(accuracy_mod(test),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "CT5120/CT5146 - Assignment 1",
   "provenance": [
    {
     "file_id": "12crGPce24mcgITZPs7hU_9CPnLAcyIq6",
     "timestamp": 1603097790764
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
